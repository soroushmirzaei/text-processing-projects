{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soroushmirzaei/text-processing-projects/blob/main/shahnameh-ferdowsi-text-generation/shahnameh-ferdowsi-text-generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIYC55FdPdC2"
      },
      "outputs": [],
      "source": [
        "#import requirement libraries\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "#import dataset query libraries\n",
        "import csv\n",
        "import json\n",
        "\n",
        "#import mathematics statics libraries\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#import machine learning deep learning libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SkBIh-h6ZzE"
      },
      "outputs": [],
      "source": [
        "#download filters-characters dataset\n",
        "!wget -q https://raw.githubusercontent.com/soroushmirzaei/text-processing-projects/main/english-language-filter-characters.txt\n",
        "!wget -q https://raw.githubusercontent.com/soroushmirzaei/text-processing-projects/main/persian-language-filter-characters.txt\n",
        "\n",
        "#download similar-characters dataset\n",
        "!wget -q https://raw.githubusercontent.com/soroushmirzaei/text-processing-projects/main/persian-language-similar-characters.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cna6blsV2ZkZ"
      },
      "outputs": [],
      "source": [
        "#define filters-list function loader\n",
        "def filter_chars(file_path):\n",
        "    filter_chars = list()\n",
        "    with open(file_path, 'r') as filters_list_file:\n",
        "        for word in filters_list_file:\n",
        "            filter_chars.append(word.strip('\\n'))\n",
        "        filters_list_file.close()\n",
        "    return filter_chars\n",
        "\n",
        "#define similar-characters function loader\n",
        "def similar_chars(file_path):\n",
        "    with open(file_path, 'r') as similar_chars_file:\n",
        "        similar_chars = json.load(similar_chars_file)\n",
        "    return similar_chars\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLhC44LW6TAd"
      },
      "outputs": [],
      "source": [
        "#load filters-characters\n",
        "eng_filter_characters = filter_chars('english-language-filter-characters.txt')\n",
        "per_filter_characters = filter_chars('persian-language-filter-characters.txt')\n",
        "\n",
        "#load similar-characters\n",
        "per_similar_characters = similar_chars('persian-language-similar-characters.json')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39pSrmpdM5xg"
      },
      "outputs": [],
      "source": [
        "#define remove filters characters function\n",
        "def remove_filter(text, filters_list):\n",
        "    characters = list(text)\n",
        "    characters_without_filters = [character for character in characters if character not in filters_list]\n",
        "    text_without_filters = ''.join(characters_without_filters)\n",
        "    return text_without_filters\n",
        "\n",
        "#define similar characters modification function\n",
        "def similar_char(text, similar_chars_dict):\n",
        "    characters = list(text)\n",
        "    similar_characters_modified_list = [similar_chars_dict.get(character,character) for character in characters]\n",
        "    similar_characters_modified_text = ''.join(similar_characters_modified_list)\n",
        "    return similar_characters_modified_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs1sANpkK_xq"
      },
      "outputs": [],
      "source": [
        "#define texts and labels list loader for csv and json files\n",
        "def texts_loader(#define file path and type\n",
        "                 file_path, file_type,\n",
        "                 #define csv and txt files index for text and labels\n",
        "                 text_index = None, header_row = True, spliter_delimiter = None,\n",
        "                 #define json file keys for texts and labels\n",
        "                 text_key = None,\n",
        "                 #define preprocessing function for texts\n",
        "                 use_filter_remover = False, filters_list = None,\n",
        "                 use_similarchars_modifier = False, similarchars_dict = None\n",
        "                 ):\n",
        "    \n",
        "    #create empty texts labels list\n",
        "    texts_list = list()\n",
        "\n",
        "    #csv file loader\n",
        "    if file_type in ['csv']:\n",
        "        with open(file_path, 'r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter = spliter_delimiter)\n",
        "            if header_row:\n",
        "                next(csv_reader)\n",
        "            for row in csv_reader:\n",
        "                text = row[text_index]\n",
        "                #optional modification function\n",
        "                if use_filter_remover:\n",
        "                    text = remove_filter(text, filters_list)\n",
        "                if use_similarchars_modifier:\n",
        "                    text = similar_char(text, similarchars_dict)\n",
        "                texts_list.append(text)\n",
        "        csv_file.close()\n",
        "\n",
        "    #txt file loader\n",
        "    if file_type in ['txt']:\n",
        "        with open(file_path, 'r') as txt_file:\n",
        "            for line in txt_file:\n",
        "                line = line.split(spliter_delimiter)\n",
        "                text = line[text_index]\n",
        "                #optional modification function\n",
        "                if use_filter_remover:\n",
        "                    text = remove_filter(text, filters_list)\n",
        "                if use_similarchars_modifier:\n",
        "                    text = similar_char(text, similarchars_dict)\n",
        "                texts_list.append(text.strip('\\n'))\n",
        "        txt_file.close()\n",
        "    \n",
        "    #json file loader\n",
        "    if file_type in ['json']:\n",
        "        with open(file_path, 'r') as json_file:\n",
        "            json_reader = json.load(json_file)\n",
        "            for item in json_reader:\n",
        "                text = item[text_key]\n",
        "                #optional modification function\n",
        "                if use_filter_remover:\n",
        "                    text = remove_filter(text, filters_list)\n",
        "                if use_similarchars_modifier:\n",
        "                    text = similar_char(text, similarchars_dict)\n",
        "                texts_list.append(text)\n",
        "        json_file.close()\n",
        "\n",
        "    return texts_list\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = texts_loader(#define file path and type\n",
        "                     file_path = '/content/shahnameh-abul-ghasem-ferdowsi', file_type = 'txt',\n",
        "                     #define csv and txt files index for text and labels\n",
        "                     text_index = 0, spliter_delimiter = '\\n',\n",
        "                     use_filter_remover = True, filters_list = eng_filter_characters,\n",
        "                     )"
      ],
      "metadata": {
        "id": "5j1v9kzdisxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2SU7J1FjSKe",
        "outputId": "cc644f87-d20e-4fdf-ef24-4ef2fac9304f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['THE FIRST KINGS ',\n",
              " '',\n",
              " '',\n",
              " 'The Reign of Kayumars ',\n",
              " '',\n",
              " 'What does the Persian poet say about the first man to seek the crown of world ',\n",
              " 'sovereignty No one has any knowledge of those first days unless he has heard ',\n",
              " 'tales passed down from father to son This is what those tales tell The first man ',\n",
              " 'to be king and to establish the ceremonies associated with the crown and throne ',\n",
              " 'was Kayumars When he became lord of the world he lived first in the ']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xws6QVTWPwbW"
      },
      "outputs": [],
      "source": [
        "#define tokenizer and sequences and padding sequences\n",
        "def texts_labels_generator(#define texts\n",
        "                           texts_list,\n",
        "                           #define filter characters list\n",
        "                           use_modified_filters = False, filters_list = None,\n",
        "                           #define json tokenizer\n",
        "                           save_tokenizer_json = False, tokenizer_filepath = None\n",
        "                           ):\n",
        "    \n",
        "    #define tokenizer filters and fit on texts\n",
        "    from keras.preprocessing.text import Tokenizer\n",
        "    if use_modified_filters:\n",
        "        filters = ''.join(filters_list)\n",
        "    else:\n",
        "        filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "\n",
        "    tokenizer = Tokenizer(filters = filters)\n",
        "    tokenizer.fit_on_texts(texts_list)\n",
        "\n",
        "    #define word_index\n",
        "    word_index = tokenizer.word_index\n",
        "    #for padding and counting out of vocab word\n",
        "    total_words = len(word_index) + 1\n",
        "\n",
        "    #save tokenizer json file\n",
        "    if save_tokenizer_json:\n",
        "        with open(tokenizer_filepath+'.json','w') as tokenizer_file:\n",
        "            json.dump(tokenizer.to_json(), tokenizer_file)\n",
        "\n",
        "    #define texts to sequences\n",
        "    texts_sequences = tokenizer.texts_to_sequences(texts_list)\n",
        "\n",
        "    #define phrase based sequences\n",
        "    phrases_sequences = list()\n",
        "\n",
        "    for text_sequence in texts_sequences:\n",
        "        for token_iter in range(1, len(text_sequence)):\n",
        "            phrase_sequence = text_sequence[:token_iter+1]\n",
        "            phrases_sequences.append(phrase_sequence)\n",
        "\n",
        "    #define maximum length of the sequences\n",
        "    maxlen = max([len(sequence) for sequence in phrases_sequences])\n",
        "\n",
        "    #define training validation pad sequences\n",
        "    from keras.preprocessing.sequence import pad_sequences\n",
        "    padded_sequences = pad_sequences(phrases_sequences, maxlen = maxlen, padding = 'pre')\n",
        "\n",
        "    #split texts and labels\n",
        "    texts = padded_sequences[:,:-1]\n",
        "    labels = padded_sequences[:,-1]\n",
        "\n",
        "    return texts, labels, maxlen, tokenizer, word_index\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels, maxlen, tokenizer, word_index = texts_labels_generator(#define texts\n",
        "                                                                      texts_list = texts,\n",
        "                                                                      #define filter characters list\n",
        "                                                                      use_modified_filters = False, filters_list = None,\n",
        "                                                                      #define json tokenizer\n",
        "                                                                      save_tokenizer_json = False, tokenizer_filepath = None)\n"
      ],
      "metadata": {
        "id": "wZEZqql-jcGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGSfyqvijnDh",
        "outputId": "c5df6b23-937b-40a5-edc4-dde9216d1f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    0,    1],\n",
              "       [   0,    0,    0, ...,    0,    1,  326],\n",
              "       [   0,    0,    0, ...,    0,    0,    1],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  475,   21, 3180],\n",
              "       [   0,    0,    0, ...,   21, 3180,    2],\n",
              "       [   0,    0,    0, ..., 3180,    2,   21]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlUz5XBTkXzd",
        "outputId": "0e84eb8a-565e-4c9d-c640-896f09f9f641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([326,  70, 462, ...,   2,  21, 768], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJ3p8PBDbFH2"
      },
      "outputs": [],
      "source": [
        "#define labels encoder\n",
        "def label_encoder(#define labels list and method\n",
        "                  labels_list,\n",
        "                  #define method binary, ordinal or onehot\n",
        "                  method, return_categories = True\n",
        "                  ):\n",
        "    \n",
        "    #ordinal and binary encoder method\n",
        "    if method in ['binary','ordinal']:\n",
        "        unique_labels = sorted(list(set(labels_list)))\n",
        "        labels_dict = {\n",
        "            label : int(unique_labels.index(label)) for label in unique_labels\n",
        "        }\n",
        "        labels = list(map(lambda label : labels_dict[label], labels_list))\n",
        "    \n",
        "    #one-hot encoder method\n",
        "    elif method in ['onehot']:\n",
        "        unique_labels = sorted(list(set(labels_list)))\n",
        "        labels_dict = {\n",
        "            label : int(unique_labels.index(label)) for label in unique_labels\n",
        "        }\n",
        "        labels_encoded = list()\n",
        "        for label in labels_list:\n",
        "            label_encoded = len(unique_labels)*[0]\n",
        "            label_number = labels_dict[label]\n",
        "            label_encoded[label_number] = 1\n",
        "            labels_encoded.append(label_encoded)\n",
        "        labels = labels_encoded\n",
        "\n",
        "    #convert list type to array\n",
        "    labels_encoded = np.array(labels)\n",
        "    \n",
        "    if return_categories:\n",
        "        return labels_encoded, labels_dict\n",
        "    else:\n",
        "        return labels_encoded\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_encoded, labels_dict = label_encoder(#define labels list and method\n",
        "                                            labels_list = labels,\n",
        "                                            #define method binary, ordinal or onehot\n",
        "                                            method = 'ordinal', return_categories = True\n",
        "                                            )\n"
      ],
      "metadata": {
        "id": "VYsK1ZRQkk-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxWfT2f9k3Yl",
        "outputId": "97015b89-febe-42aa-e6a5-2a1d26e0e53f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([325,  69, 461, ...,   1,  20, 767])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRHnC1EAk5ke",
        "outputId": "be425f57-31c8-45bd-fc62-8e3f98b9786c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(363853,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define pre-trained words dictionary loader\n",
        "def word_dict_loader(#define file path and file type\n",
        "                     file_path, file_type,\n",
        "                     #define txt and csv file type args\n",
        "                     word_index = None, vector_index = None, header = True, spliter_delimiter = None,\n",
        "                     use_word_spliter = False, word_spliter = None, word_split_index = None,\n",
        "                     #define json file type args\n",
        "                     word_key = None, vector_key = None,\n",
        "                     ):\n",
        "    \n",
        "    word_dict = dict()\n",
        "\n",
        "    #define txt vec loader\n",
        "    if file_type in ['txt', 'vec']:\n",
        "        with open(file_path, 'r') as word_dict_file:\n",
        "            if header:\n",
        "                next(word_dict_file)\n",
        "            for row in word_dict_file:\n",
        "                row = row.split(spliter_delimiter)\n",
        "                if use_word_spliter:\n",
        "                    word = row[word_index].split(word_spliter)[word_split_index]\n",
        "                else:\n",
        "                    word = row[word_index]\n",
        "                vectors = np.array(row[vector_index:], dtype = 'float32')\n",
        "                word_dict[word] = vectors\n",
        "\n",
        "    #define csv loader\n",
        "    elif file_type in ['csv']:\n",
        "        with open(file_path, 'r') as word_dict_file:\n",
        "            word_dict_file = csv.reader(word_dict_file, delimiter = spliter_delimiter)\n",
        "            if header:\n",
        "                next(word_dict_file)\n",
        "            for row in word_dict_file:\n",
        "                if use_word_spliter:\n",
        "                    word = row[word_index].split(word_spliter)[word_split_index]\n",
        "                else:\n",
        "                    word = row[word_index]\n",
        "                vectors = np.array(row[vector_index:], dtype = 'float32')\n",
        "                word_dict[word] = vectors\n",
        "                \n",
        "    #define json loader\n",
        "    elif file_type in ['json']:\n",
        "        with open(file_path, 'r') as word_dict_file:\n",
        "            word_dict_file = json.load(word_dict_file)\n",
        "            for item in word_dict_file:\n",
        "                word = item[word_key]\n",
        "                vectors = np.array(item[vector_key], dtype = 'float32')\n",
        "                word_dict[word] = vectors\n",
        "\n",
        "    #word dict params\n",
        "    word_dict_size = len(word_dict)\n",
        "    word_dict_dim = list(word_dict.values())[0].shape[0]\n",
        "\n",
        "    return word_dict, word_dict_size, word_dict_dim\n"
      ],
      "metadata": {
        "id": "brRWvKPSp4QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define pre-trained embedding word vectors\n",
        "def embd_weights_loader(#define word dictionary and word index\n",
        "                        word_dict, word_index, dimension\n",
        "                        ):\n",
        "    \n",
        "    #create embedding weights\n",
        "    embed_weights = np.zeros([len(word_index)+1, dimension])\n",
        "\n",
        "    for word, index in word_index.items():\n",
        "        if word in word_dict:\n",
        "            embed_weights[index] = word_dict[word]\n",
        "\n",
        "    #embedding layer params\n",
        "    vocab_size = embed_weights.shape[0]\n",
        "    embed_dim = embed_weights.shape[1]\n",
        "\n",
        "    return embed_weights, vocab_size, embed_dim\n"
      ],
      "metadata": {
        "id": "fFr4DSbYpYjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlRqac9W2DWL"
      },
      "outputs": [],
      "source": [
        "#define model\n",
        "def create_model(#define input shape\n",
        "                 input_shape = None,\n",
        "                 #define embedding layer parameters\n",
        "                 use_pretraind_embd = False, vocab_size = None, embd_dim = None,\n",
        "                 sequence_len = None, embed_weights = None,\n",
        "                 #define type of layer and parameters\n",
        "                 use_lstm = False, use_gru = False, use_conv = False,\n",
        "                 #define lstm layers parameters\n",
        "                 lstm_layers_num = None, lstm_layers_units = None,\n",
        "                 #define gru layers parameters\n",
        "                 gru_layers_num = None, gru_layers_units = None,\n",
        "                 #define convolution layers parameters\n",
        "                 conv_layers_num = None, conv_layers_filters = None, conv_layers_kernel = None,\n",
        "                 #define convolution layers sub layers\n",
        "                 use_max_pool = False, max_pool_size = None,\n",
        "                 #define dense layer feeder\n",
        "                 use_global_max_pool = False, use_global_avg_pool = False, use_flatten = False,\n",
        "                 use_feeder_dropout = False, feeder_dropout_ratio = None,\n",
        "                 #define dense head layers\n",
        "                 use_dense_layer = False, dense_layers_num = None, dense_layers_units = None,\n",
        "                 #define dense layers dropout parameters\n",
        "                 use_dense_dropout = False, dense_dropout_ratio = None,\n",
        "                 #define output layer parameters\n",
        "                 output_layer_unit = None, output_layer_activation = None,\n",
        "                 #define model compiler parameters\n",
        "                 optimizer = None, loss = None, metrics = None\n",
        "                 ):\n",
        "    \n",
        "    #define input layer\n",
        "    input = keras.Input(shape = input_shape)\n",
        "\n",
        "    #define embedding layer and parameters\n",
        "    if use_pretraind_embd:\n",
        "        out = keras.layers.Embedding(input_dim = vocab_size, output_dim = embd_dim, input_length = sequence_len,\n",
        "                                     weights = [embed_weights], trainable = False)(input)\n",
        "    else:\n",
        "        out = keras.layers.Embedding(input_dim = vocab_size, output_dim = embd_dim, input_length = sequence_len)(input)\n",
        "\n",
        "    #define type of layer and parameters\n",
        "    #lstm type layers\n",
        "    if use_lstm:\n",
        "        sequence_return = (lstm_layers_num - 1)*[True]\n",
        "        sequence_return.append(False)\n",
        "        for layer_num in range(lstm_layers_num):\n",
        "            out = keras.layers.Bidirectional(keras.layers.LSTM(lstm_layers_units[layer_num],\n",
        "                                                               return_sequences = sequence_return[layer_num]))(out)\n",
        "\n",
        "    #gru type layers\n",
        "    elif use_gru:\n",
        "        sequence_return = (gru_layers_num - 1)*[True]\n",
        "        sequence_return.append(False)\n",
        "        for layer_num in range(gru_layers_num):\n",
        "            out = keras.layers.Bidirectional(keras.layers.GRU(gru_layers_units[layer_num],\n",
        "                                                              return_sequences = sequence_return[layer_num]))(out)\n",
        "    \n",
        "    #convolution type layer\n",
        "    elif use_conv:\n",
        "        for layer_num in range(conv_layers_num):\n",
        "            out = keras.layers.Conv1D(filters = conv_layers_filters[layer_num], kernel_size = conv_layers_kernel[layer_num],\n",
        "                                      activation = 'relu')(out)\n",
        "            if use_max_pool[layer_num]:\n",
        "                out = keras.layers.MaxPool1D(max_pool_size[layer_num])(out)\n",
        "\n",
        "\n",
        "    #dense layers feeder layer\n",
        "    #global max pool type layer\n",
        "    if use_global_max_pool:\n",
        "        out = keras.layers.GlobalMaxPooling1D()(out)\n",
        "        \n",
        "    #global average pool type layer\n",
        "    elif use_global_avg_pool:\n",
        "        out = keras.layers.GlobalAveragePooling1D()(out)\n",
        "\n",
        "    #flatten type layer\n",
        "    elif use_flatten:\n",
        "        out = keras.layers.Flatten()(out)\n",
        "\n",
        "    #define feeder dropout layer\n",
        "    if use_feeder_dropout:\n",
        "        out = keras.layers.Dropout(feeder_dropout_ratio)(out)\n",
        "\n",
        "\n",
        "    #define dense head layers\n",
        "    if use_dense_layer:\n",
        "        for layer_num in range(dense_layers_num):\n",
        "            out = keras.layers.Dense(dense_layers_units[layer_num], activation = 'relu')(out)\n",
        "            if use_dense_dropout[layer_num]:\n",
        "                out = keras.layers.Dropout(dense_dropout_ratio[layer_num])(out)\n",
        "    \n",
        "    #define output layer\n",
        "    output = keras.layers.Dense(output_layer_unit, activation = output_layer_activation)(out)\n",
        "\n",
        "    #define model\n",
        "    model = keras.models.Model(inputs = input, outputs = output)\n",
        "\n",
        "\n",
        "    #compile model\n",
        "    model.compile(optimizer = optimizer,\n",
        "                  loss = loss,\n",
        "                  metrics = metrics)\n",
        "    \n",
        "    return model\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(#define input shape\n",
        "                     input_shape = maxlen - 1,\n",
        "                     #define embedding layer parameters\n",
        "                     use_pretraind_embd = False, vocab_size = len(word_index) + 1 , embd_dim = 128,\n",
        "                     sequence_len = maxlen - 1, embed_weights = None,\n",
        "                     #define type of layer and parameters\n",
        "                     use_lstm = True, use_gru = False, use_conv = False,\n",
        "                     #define lstm layers parameters\n",
        "                     lstm_layers_num = 2, lstm_layers_units = [64, 128],\n",
        "                     #define gru layers parameters\n",
        "                     gru_layers_num = None, gru_layers_units = None,\n",
        "                     #define convolution layers parameters\n",
        "                     conv_layers_num = None, conv_layers_filters = None, conv_layers_kernel = None,\n",
        "                     #define convolution layers sub layers\n",
        "                     use_max_pool = False, max_pool_size = None,\n",
        "                     #define dense layer feeder\n",
        "                     use_global_max_pool = False, use_global_avg_pool = False, use_flatten = False,\n",
        "                     use_feeder_dropout = True, feeder_dropout_ratio = 0.2,\n",
        "                     #define dense head layers\n",
        "                     dense_layers_num = None, dense_layers_units = None,\n",
        "                     #define dense layers dropout parameters\n",
        "                     use_dense_dropout = False, dense_dropout_ratio = None,\n",
        "                     #define output layer parameters\n",
        "                     output_layer_unit = len(labels_dict), output_layer_activation = 'softmax',\n",
        "                     #define model compiler parameters\n",
        "                     optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy'\n",
        "                     )"
      ],
      "metadata": {
        "id": "7cApqHwGmYYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model summary\n",
        "model.summary(120)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoM66pE6oxL0",
        "outputId": "ebaeeb26-fcc0-4772-9616-5993324dbd37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "________________________________________________________________________________________________________________________\n",
            " Layer (type)                                         Output Shape                                    Param #           \n",
            "========================================================================================================================\n",
            " input_2 (InputLayer)                                 [(None, 20)]                                    0                 \n",
            "                                                                                                                        \n",
            " embedding_1 (Embedding)                              (None, 20, 128)                                 1527040           \n",
            "                                                                                                                        \n",
            " bidirectional_2 (Bidirectional)                      (None, 20, 128)                                 98816             \n",
            "                                                                                                                        \n",
            " bidirectional_3 (Bidirectional)                      (None, 256)                                     263168            \n",
            "                                                                                                                        \n",
            " dropout_1 (Dropout)                                  (None, 256)                                     0                 \n",
            "                                                                                                                        \n",
            " dense_1 (Dense)                                      (None, 11404)                                   2930828           \n",
            "                                                                                                                        \n",
            "========================================================================================================================\n",
            "Total params: 4,819,852\n",
            "Trainable params: 4,819,852\n",
            "Non-trainable params: 0\n",
            "________________________________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fit model\n",
        "model.fit(texts, labels_encoded, epochs = 200, steps_per_epoch = 2048)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQcBis-no21v",
        "outputId": "365cda8b-b355-4578-abc4-1c87fc5772ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2048/2048 [==============================] - 42s 18ms/step - loss: 6.1214 - accuracy: 0.0916\n",
            "Epoch 2/200\n",
            "2048/2048 [==============================] - 38s 19ms/step - loss: 5.5767 - accuracy: 0.1323\n",
            "Epoch 3/200\n",
            "2048/2048 [==============================] - 37s 18ms/step - loss: 5.3131 - accuracy: 0.1484\n",
            "Epoch 4/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 5.1280 - accuracy: 0.1602\n",
            "Epoch 5/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 4.9897 - accuracy: 0.1691\n",
            "Epoch 6/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 4.8735 - accuracy: 0.1756\n",
            "Epoch 7/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 4.7723 - accuracy: 0.1813\n",
            "Epoch 8/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 4.6810 - accuracy: 0.1872\n",
            "Epoch 9/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 4.5953 - accuracy: 0.1919\n",
            "Epoch 10/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 4.5102 - accuracy: 0.1975\n",
            "Epoch 11/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 4.4306 - accuracy: 0.2027\n",
            "Epoch 12/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 4.3506 - accuracy: 0.2071\n",
            "Epoch 13/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 4.2733 - accuracy: 0.2133\n",
            "Epoch 14/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 4.1971 - accuracy: 0.2186\n",
            "Epoch 15/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 4.1209 - accuracy: 0.2238\n",
            "Epoch 16/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 4.0491 - accuracy: 0.2300\n",
            "Epoch 17/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.9764 - accuracy: 0.2357\n",
            "Epoch 18/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.9089 - accuracy: 0.2422\n",
            "Epoch 19/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.8425 - accuracy: 0.2480\n",
            "Epoch 20/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 3.7795 - accuracy: 0.2547\n",
            "Epoch 21/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 3.7181 - accuracy: 0.2621\n",
            "Epoch 22/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 3.6564 - accuracy: 0.2683\n",
            "Epoch 23/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.6008 - accuracy: 0.2733\n",
            "Epoch 24/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.5462 - accuracy: 0.2803\n",
            "Epoch 25/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.4949 - accuracy: 0.2867\n",
            "Epoch 26/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 3.4413 - accuracy: 0.2945\n",
            "Epoch 27/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 3.3942 - accuracy: 0.3006\n",
            "Epoch 28/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.3489 - accuracy: 0.3056\n",
            "Epoch 29/200\n",
            "2048/2048 [==============================] - 38s 19ms/step - loss: 3.3048 - accuracy: 0.3110\n",
            "Epoch 30/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.2602 - accuracy: 0.3177\n",
            "Epoch 31/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 3.2182 - accuracy: 0.3240\n",
            "Epoch 32/200\n",
            "2048/2048 [==============================] - 38s 18ms/step - loss: 3.1811 - accuracy: 0.3289\n",
            "Epoch 33/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 3.1406 - accuracy: 0.3349\n",
            "Epoch 34/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.1088 - accuracy: 0.3387\n",
            "Epoch 35/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.0691 - accuracy: 0.3450\n",
            "Epoch 36/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.0389 - accuracy: 0.3493\n",
            "Epoch 37/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 3.0065 - accuracy: 0.3536\n",
            "Epoch 38/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.9759 - accuracy: 0.3585\n",
            "Epoch 39/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.9464 - accuracy: 0.3639\n",
            "Epoch 40/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 2.9189 - accuracy: 0.3676\n",
            "Epoch 41/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.8884 - accuracy: 0.3725\n",
            "Epoch 42/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.8680 - accuracy: 0.3751\n",
            "Epoch 43/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.8359 - accuracy: 0.3800\n",
            "Epoch 44/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.8115 - accuracy: 0.3840\n",
            "Epoch 45/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.7868 - accuracy: 0.3879\n",
            "Epoch 46/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.7624 - accuracy: 0.3915\n",
            "Epoch 47/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.7446 - accuracy: 0.3950\n",
            "Epoch 48/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.7189 - accuracy: 0.3992\n",
            "Epoch 49/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.7063 - accuracy: 0.4000\n",
            "Epoch 50/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.6776 - accuracy: 0.4053\n",
            "Epoch 51/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.6588 - accuracy: 0.4084\n",
            "Epoch 52/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.6419 - accuracy: 0.4111\n",
            "Epoch 53/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.6178 - accuracy: 0.4155\n",
            "Epoch 54/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 2.6059 - accuracy: 0.4184\n",
            "Epoch 55/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.5930 - accuracy: 0.4196\n",
            "Epoch 56/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.5681 - accuracy: 0.4231\n",
            "Epoch 57/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.5563 - accuracy: 0.4268\n",
            "Epoch 58/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.5367 - accuracy: 0.4296\n",
            "Epoch 59/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.5266 - accuracy: 0.4311\n",
            "Epoch 60/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 2.5068 - accuracy: 0.4355\n",
            "Epoch 61/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.4991 - accuracy: 0.4362\n",
            "Epoch 62/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.4813 - accuracy: 0.4384\n",
            "Epoch 63/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.4702 - accuracy: 0.4407\n",
            "Epoch 64/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.4555 - accuracy: 0.4433\n",
            "Epoch 65/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.4437 - accuracy: 0.4448\n",
            "Epoch 66/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.4291 - accuracy: 0.4474\n",
            "Epoch 67/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.4180 - accuracy: 0.4491\n",
            "Epoch 68/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.4075 - accuracy: 0.4518\n",
            "Epoch 69/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.3934 - accuracy: 0.4533\n",
            "Epoch 70/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.3852 - accuracy: 0.4555\n",
            "Epoch 71/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.3739 - accuracy: 0.4575\n",
            "Epoch 72/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.3620 - accuracy: 0.4592\n",
            "Epoch 73/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 2.3479 - accuracy: 0.4613\n",
            "Epoch 74/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 2.3425 - accuracy: 0.4626\n",
            "Epoch 75/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.3299 - accuracy: 0.4650\n",
            "Epoch 76/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.3229 - accuracy: 0.4659\n",
            "Epoch 77/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.3154 - accuracy: 0.4682\n",
            "Epoch 78/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.3037 - accuracy: 0.4693\n",
            "Epoch 79/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.2962 - accuracy: 0.4708\n",
            "Epoch 80/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.2886 - accuracy: 0.4727\n",
            "Epoch 81/200\n",
            "2048/2048 [==============================] - 32s 15ms/step - loss: 2.2767 - accuracy: 0.4745\n",
            "Epoch 82/200\n",
            "2048/2048 [==============================] - 32s 16ms/step - loss: 2.2696 - accuracy: 0.4753\n",
            "Epoch 83/200\n",
            "2048/2048 [==============================] - 32s 16ms/step - loss: 2.2622 - accuracy: 0.4763\n",
            "Epoch 84/200\n",
            "2048/2048 [==============================] - 32s 16ms/step - loss: 2.2547 - accuracy: 0.4784\n",
            "Epoch 85/200\n",
            "2048/2048 [==============================] - 32s 16ms/step - loss: 2.2488 - accuracy: 0.4781\n",
            "Epoch 86/200\n",
            "2048/2048 [==============================] - 32s 16ms/step - loss: 2.2427 - accuracy: 0.4805\n",
            "Epoch 87/200\n",
            "2048/2048 [==============================] - 32s 16ms/step - loss: 2.2311 - accuracy: 0.4828\n",
            "Epoch 88/200\n",
            "2048/2048 [==============================] - 32s 16ms/step - loss: 2.2217 - accuracy: 0.4837\n",
            "Epoch 89/200\n",
            "2048/2048 [==============================] - 32s 16ms/step - loss: 2.2213 - accuracy: 0.4840\n",
            "Epoch 90/200\n",
            "2048/2048 [==============================] - 32s 16ms/step - loss: 2.2129 - accuracy: 0.4852\n",
            "Epoch 91/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.2065 - accuracy: 0.4860\n",
            "Epoch 92/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.2011 - accuracy: 0.4874\n",
            "Epoch 93/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1929 - accuracy: 0.4898\n",
            "Epoch 94/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1894 - accuracy: 0.4901\n",
            "Epoch 95/200\n",
            "2048/2048 [==============================] - 30s 15ms/step - loss: 2.1784 - accuracy: 0.4911\n",
            "Epoch 96/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1751 - accuracy: 0.4913\n",
            "Epoch 97/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1688 - accuracy: 0.4924\n",
            "Epoch 98/200\n",
            "2048/2048 [==============================] - 30s 15ms/step - loss: 2.1589 - accuracy: 0.4956\n",
            "Epoch 99/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1604 - accuracy: 0.4947\n",
            "Epoch 100/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1553 - accuracy: 0.4960\n",
            "Epoch 101/200\n",
            "2048/2048 [==============================] - 30s 15ms/step - loss: 2.1433 - accuracy: 0.4980\n",
            "Epoch 102/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1404 - accuracy: 0.4984\n",
            "Epoch 103/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1392 - accuracy: 0.4987\n",
            "Epoch 104/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1344 - accuracy: 0.4992\n",
            "Epoch 105/200\n",
            "2048/2048 [==============================] - 30s 15ms/step - loss: 2.1225 - accuracy: 0.5023\n",
            "Epoch 106/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1219 - accuracy: 0.5023\n",
            "Epoch 107/200\n",
            "2048/2048 [==============================] - 30s 15ms/step - loss: 2.1192 - accuracy: 0.5025\n",
            "Epoch 108/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1192 - accuracy: 0.5031\n",
            "Epoch 109/200\n",
            "2048/2048 [==============================] - 30s 15ms/step - loss: 2.1055 - accuracy: 0.5044\n",
            "Epoch 110/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.1036 - accuracy: 0.5043\n",
            "Epoch 111/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0999 - accuracy: 0.5061\n",
            "Epoch 112/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0965 - accuracy: 0.5070\n",
            "Epoch 113/200\n",
            "2048/2048 [==============================] - 30s 15ms/step - loss: 2.1003 - accuracy: 0.5055\n",
            "Epoch 114/200\n",
            "2048/2048 [==============================] - 30s 15ms/step - loss: 2.0814 - accuracy: 0.5096\n",
            "Epoch 115/200\n",
            "2048/2048 [==============================] - 30s 15ms/step - loss: 2.0870 - accuracy: 0.5081\n",
            "Epoch 116/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0814 - accuracy: 0.5086\n",
            "Epoch 117/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 2.0742 - accuracy: 0.5107\n",
            "Epoch 118/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 2.0674 - accuracy: 0.5120\n",
            "Epoch 119/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 2.0666 - accuracy: 0.5112\n",
            "Epoch 120/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 2.0668 - accuracy: 0.5113\n",
            "Epoch 121/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 2.0577 - accuracy: 0.5133\n",
            "Epoch 122/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 2.0665 - accuracy: 0.5119\n",
            "Epoch 123/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 2.0573 - accuracy: 0.5131\n",
            "Epoch 124/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 2.0494 - accuracy: 0.5152\n",
            "Epoch 125/200\n",
            "2048/2048 [==============================] - 32s 16ms/step - loss: 2.0418 - accuracy: 0.5171\n",
            "Epoch 126/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0420 - accuracy: 0.5169\n",
            "Epoch 127/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0380 - accuracy: 0.5164\n",
            "Epoch 128/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0379 - accuracy: 0.5173\n",
            "Epoch 129/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0326 - accuracy: 0.5181\n",
            "Epoch 130/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0276 - accuracy: 0.5183\n",
            "Epoch 131/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0284 - accuracy: 0.5185\n",
            "Epoch 132/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0204 - accuracy: 0.5197\n",
            "Epoch 133/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0143 - accuracy: 0.5211\n",
            "Epoch 134/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0201 - accuracy: 0.5203\n",
            "Epoch 135/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0076 - accuracy: 0.5221\n",
            "Epoch 136/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0143 - accuracy: 0.5219\n",
            "Epoch 137/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0072 - accuracy: 0.5231\n",
            "Epoch 138/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0024 - accuracy: 0.5230\n",
            "Epoch 139/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0075 - accuracy: 0.5229\n",
            "Epoch 140/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 2.0031 - accuracy: 0.5223\n",
            "Epoch 141/200\n",
            "2048/2048 [==============================] - 31s 15ms/step - loss: 1.9937 - accuracy: 0.5261\n",
            "Epoch 142/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 2.0014 - accuracy: 0.5223\n",
            "Epoch 143/200\n",
            "2048/2048 [==============================] - 36s 18ms/step - loss: 1.9899 - accuracy: 0.5255\n",
            "Epoch 144/200\n",
            "2048/2048 [==============================] - 36s 18ms/step - loss: 1.9985 - accuracy: 0.5247\n",
            "Epoch 145/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.9826 - accuracy: 0.5270\n",
            "Epoch 146/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9797 - accuracy: 0.5279\n",
            "Epoch 147/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.9838 - accuracy: 0.5277\n",
            "Epoch 148/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.9738 - accuracy: 0.5292\n",
            "Epoch 149/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.9754 - accuracy: 0.5285\n",
            "Epoch 150/200\n",
            "2048/2048 [==============================] - 36s 18ms/step - loss: 1.9790 - accuracy: 0.5273\n",
            "Epoch 151/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.9641 - accuracy: 0.5304\n",
            "Epoch 152/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9674 - accuracy: 0.5298\n",
            "Epoch 153/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9702 - accuracy: 0.5296\n",
            "Epoch 154/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.9663 - accuracy: 0.5306\n",
            "Epoch 155/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.9662 - accuracy: 0.5306\n",
            "Epoch 156/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.9587 - accuracy: 0.5318\n",
            "Epoch 157/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9587 - accuracy: 0.5318\n",
            "Epoch 158/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9578 - accuracy: 0.5324\n",
            "Epoch 159/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9567 - accuracy: 0.5323\n",
            "Epoch 160/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9456 - accuracy: 0.5336\n",
            "Epoch 161/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9553 - accuracy: 0.5326\n",
            "Epoch 162/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9490 - accuracy: 0.5331\n",
            "Epoch 163/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9439 - accuracy: 0.5338\n",
            "Epoch 164/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 1.9406 - accuracy: 0.5355\n",
            "Epoch 165/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 1.9419 - accuracy: 0.5341\n",
            "Epoch 166/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 1.9387 - accuracy: 0.5350\n",
            "Epoch 167/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 1.9394 - accuracy: 0.5358\n",
            "Epoch 168/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9316 - accuracy: 0.5365\n",
            "Epoch 169/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 1.9324 - accuracy: 0.5354\n",
            "Epoch 170/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 1.9331 - accuracy: 0.5363\n",
            "Epoch 171/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 1.9302 - accuracy: 0.5359\n",
            "Epoch 172/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9293 - accuracy: 0.5371\n",
            "Epoch 173/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 1.9289 - accuracy: 0.5372\n",
            "Epoch 174/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 1.9322 - accuracy: 0.5368\n",
            "Epoch 175/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9185 - accuracy: 0.5389\n",
            "Epoch 176/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 1.9234 - accuracy: 0.5390\n",
            "Epoch 177/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 1.9172 - accuracy: 0.5391\n",
            "Epoch 178/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 1.9173 - accuracy: 0.5390\n",
            "Epoch 179/200\n",
            "2048/2048 [==============================] - 33s 16ms/step - loss: 1.9156 - accuracy: 0.5398\n",
            "Epoch 180/200\n",
            "2048/2048 [==============================] - 34s 16ms/step - loss: 1.9182 - accuracy: 0.5392\n",
            "Epoch 181/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9221 - accuracy: 0.5385\n",
            "Epoch 182/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9097 - accuracy: 0.5395\n",
            "Epoch 183/200\n",
            "2048/2048 [==============================] - 36s 18ms/step - loss: 1.9080 - accuracy: 0.5421\n",
            "Epoch 184/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9092 - accuracy: 0.5406\n",
            "Epoch 185/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9108 - accuracy: 0.5403\n",
            "Epoch 186/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9075 - accuracy: 0.5422\n",
            "Epoch 187/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.9062 - accuracy: 0.5403\n",
            "Epoch 188/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9028 - accuracy: 0.5425\n",
            "Epoch 189/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9045 - accuracy: 0.5421\n",
            "Epoch 190/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9026 - accuracy: 0.5422\n",
            "Epoch 191/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9007 - accuracy: 0.5416\n",
            "Epoch 192/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.8956 - accuracy: 0.5432\n",
            "Epoch 193/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.8936 - accuracy: 0.5445\n",
            "Epoch 194/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.8944 - accuracy: 0.5435\n",
            "Epoch 195/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.8939 - accuracy: 0.5434\n",
            "Epoch 196/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.8895 - accuracy: 0.5454\n",
            "Epoch 197/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.9155 - accuracy: 0.5397\n",
            "Epoch 198/200\n",
            "2048/2048 [==============================] - 34s 17ms/step - loss: 1.8936 - accuracy: 0.5443\n",
            "Epoch 199/200\n",
            "2048/2048 [==============================] - 35s 17ms/step - loss: 1.8803 - accuracy: 0.5470\n",
            "Epoch 200/200\n",
            "1445/2048 [====================>.........] - ETA: 10s - loss: 1.9192 - accuracy: 0.5390WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 409600 batches). You may need to use the repeat() function when building your dataset.\n",
            "2048/2048 [==============================] - 24s 12ms/step - loss: 1.9193 - accuracy: 0.5391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff5261f4b50>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot model training loss\n",
        "pd.DataFrame(model.history.history)[['loss']].plot(figsize = (9, 6), linewidth = 3)\n",
        "plt.grid(linestyle = '--', linewidth = 2)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "r9WlvK5vzfSG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "5f5561c2-3bd5-4fba-8557-e302afe2a624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot model training accuracy\n",
        "pd.DataFrame(model.history.history)[['accuracy']].plot(figsize = (9, 6), linewidth = 3)\n",
        "plt.grid(linestyle = '--', linewidth = 2)\n",
        "plt.ylim(0,1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v4gmV_f1z1nM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "5d8c9ef4-7c99-4721-c91b-2eee1372378a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "train_set_eval = model.evaluate(texts, labels_encoded, verbose = 0,  steps = 2048)\n",
        "print(f'Training Set Evaluation:\\n\\tLoss: {round(train_set_eval[0],4)}\\tAccuracy: {100*round(train_set_eval[1],4)}%')\n"
      ],
      "metadata": {
        "id": "a1fGgl5a0Ms8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a086d01c-7482-47d8-b5c0-73c8405d3b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2048 batches). You may need to use the repeat() function when building your dataset.\n",
            "Training Set Evaluation:\n",
            "\tLoss: 1.388\tAccuracy: 66.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define text generator based on model\n",
        "def text_generator(#define text and numbert of iteration\n",
        "                   input_text, iteration,\n",
        "                   #define tokenizer and maxlen\n",
        "                   tokenizer, maxlen, word_index,\n",
        "                   #define labels categories and model\n",
        "                   labels_dict, model, \n",
        "                   ):\n",
        "    \n",
        "    input_text = str(input_text)\n",
        "    key_values_labels = dict([(key,value) for value, key in labels_dict.items()])\n",
        "    index_word = dict([(key, value) for value, key in word_index.items()])\n",
        "\n",
        "    for iter in range(iteration):\n",
        "        text = tokenizer.texts_to_sequences([input_text])\n",
        "        text = keras.preprocessing.sequence.pad_sequences(text, padding = 'pre', maxlen = maxlen - 1)\n",
        "        predict = model.predict(text)\n",
        "        predict = np.argmax(predict, axis = -1)[0]\n",
        "        predict = key_values_labels[predict]\n",
        "        predict = index_word[predict]\n",
        "        input_text = input_text + \" \" + predict\n",
        "    \n",
        "    return input_text.title()\n"
      ],
      "metadata": {
        "id": "4veh4dxp72m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate the text\n",
        "generated_text = text_generator(#define text and numbert of iteration\n",
        "                                input_text = 'We Never Die In Heart', iteration = 20,\n",
        "                                #define tokenizer and maxlen\n",
        "                                tokenizer = tokenizer, maxlen = maxlen, word_index = word_index,\n",
        "                                #define labels categories and model\n",
        "                                labels_dict = labels_dict, model = model,\n",
        "                                )\n",
        "#print out the generated text\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "id": "TmfAFEdhLQKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce23fd2f-e92c-4f19-b4b8-6b2574d8e6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We Never Die In Heart And None Of Us Sent His Army To Our Armys People We Are Not To Agree For Him And You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "model.save('/content/model.h5')\n"
      ],
      "metadata": {
        "id": "gikdU4aO0Lgg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "shahnameh-ferdowsi-text-generation.ipynb",
      "provenance": [],
      "mount_file_id": "1YqkKxxHYU3J4ituglLL786xGYjnko5FS",
      "authorship_tag": "ABX9TyOvH/PRufr9KbQOCqNQBppF",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}