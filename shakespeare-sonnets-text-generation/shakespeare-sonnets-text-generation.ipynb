{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soroushmirzaei/text-processing-projects/blob/main/shakespeare-sonnets-text-generation/shakespeare-sonnets-text-generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIYC55FdPdC2"
      },
      "outputs": [],
      "source": [
        "#import requirement libraries\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "#import dataset query libraries\n",
        "import csv\n",
        "import json\n",
        "\n",
        "#import mathematics statics libraries\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#import machine learning deep learning libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download dataset\n",
        "!gdown 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaLj9-IliU3V",
        "outputId": "d414c110-0b03-43c7-a5a3-626a245f9344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
            "To: /content/sonnets.txt\n",
            "\r  0% 0.00/93.6k [00:00<?, ?B/s]\r100% 93.6k/93.6k [00:00<00:00, 57.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SkBIh-h6ZzE"
      },
      "outputs": [],
      "source": [
        "#download filters-characters dataset\n",
        "!wget -q https://raw.githubusercontent.com/soroushmirzaei/text-processing-projects/main/english-language-filter-characters.txt\n",
        "!wget -q https://raw.githubusercontent.com/soroushmirzaei/text-processing-projects/main/persian-language-filter-characters.txt\n",
        "\n",
        "#download similar-characters dataset\n",
        "!wget -q https://raw.githubusercontent.com/soroushmirzaei/text-processing-projects/main/persian-language-similar-characters.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cna6blsV2ZkZ"
      },
      "outputs": [],
      "source": [
        "#define filters-list function loader\n",
        "def filter_chars(file_path):\n",
        "    filter_chars = list()\n",
        "    with open(file_path, 'r') as filters_list_file:\n",
        "        for word in filters_list_file:\n",
        "            filter_chars.append(word.strip('\\n'))\n",
        "        filters_list_file.close()\n",
        "    return filter_chars\n",
        "\n",
        "#define similar-characters function loader\n",
        "def similar_chars(file_path):\n",
        "    with open(file_path, 'r') as similar_chars_file:\n",
        "        similar_chars = json.load(similar_chars_file)\n",
        "    return similar_chars\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLhC44LW6TAd"
      },
      "outputs": [],
      "source": [
        "#load filters-characters\n",
        "eng_filter_characters = filter_chars('english-language-filter-characters.txt')\n",
        "per_filter_characters = filter_chars('persian-language-filter-characters.txt')\n",
        "\n",
        "#load similar-characters\n",
        "per_similar_characters = similar_chars('persian-language-similar-characters.json')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39pSrmpdM5xg"
      },
      "outputs": [],
      "source": [
        "#define remove filters characters function\n",
        "def remove_filter(text, filters_list):\n",
        "    characters = list(text)\n",
        "    characters_without_filters = [character for character in characters if character not in filters_list]\n",
        "    text_without_filters = ''.join(characters_without_filters)\n",
        "    return text_without_filters\n",
        "\n",
        "#define similar characters modification function\n",
        "def similar_char(text, similar_chars_dict):\n",
        "    characters = list(text)\n",
        "    similar_characters_modified_list = [similar_chars_dict.get(character,character) for character in characters]\n",
        "    similar_characters_modified_text = ''.join(similar_characters_modified_list)\n",
        "    return similar_characters_modified_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs1sANpkK_xq"
      },
      "outputs": [],
      "source": [
        "#define texts and labels list loader for csv and json files\n",
        "def texts_loader(#define file path and type\n",
        "                 file_path, file_type,\n",
        "                 #define csv and txt files index for text and labels\n",
        "                 text_index = None, header_row = True, spliter_delimiter = None,\n",
        "                 #define json file keys for texts and labels\n",
        "                 text_key = None,\n",
        "                 #define preprocessing function for texts\n",
        "                 use_filter_remover = False, filters_list = None,\n",
        "                 use_similarchars_modifier = False, similarchars_dict = None\n",
        "                 ):\n",
        "    \n",
        "    #create empty texts labels list\n",
        "    texts_list = list()\n",
        "\n",
        "    #csv file loader\n",
        "    if file_type in ['csv']:\n",
        "        with open(file_path, 'r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter = spliter_delimiter)\n",
        "            if header_row:\n",
        "                next(csv_reader)\n",
        "            for row in csv_reader:\n",
        "                text = row[text_index]\n",
        "                #optional modification function\n",
        "                if use_filter_remover:\n",
        "                    text = remove_filter(text, filters_list)\n",
        "                if use_similarchars_modifier:\n",
        "                    text = similar_char(text, similarchars_dict)\n",
        "                texts_list.append(text)\n",
        "        csv_file.close()\n",
        "\n",
        "    #txt file loader\n",
        "    if file_type in ['txt']:\n",
        "        with open(file_path, 'r') as txt_file:\n",
        "            for line in txt_file:\n",
        "                line = line.split(spliter_delimiter)\n",
        "                text = line[text_index]\n",
        "                #optional modification function\n",
        "                if use_filter_remover:\n",
        "                    text = remove_filter(text, filters_list)\n",
        "                if use_similarchars_modifier:\n",
        "                    text = similar_char(text, similarchars_dict)\n",
        "                texts_list.append(text.strip('\\n'))\n",
        "        txt_file.close()\n",
        "    \n",
        "    #json file loader\n",
        "    if file_type in ['json']:\n",
        "        with open(file_path, 'r') as json_file:\n",
        "            json_reader = json.load(json_file)\n",
        "            for item in json_reader:\n",
        "                text = item[text_key]\n",
        "                #optional modification function\n",
        "                if use_filter_remover:\n",
        "                    text = remove_filter(text, filters_list)\n",
        "                if use_similarchars_modifier:\n",
        "                    text = similar_char(text, similarchars_dict)\n",
        "                texts_list.append(text)\n",
        "        json_file.close()\n",
        "\n",
        "    return texts_list\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = texts_loader(#define file path and type\n",
        "                     file_path = '/content/sonnets.txt', file_type = 'txt',\n",
        "                     #define csv and txt files index for text and labels\n",
        "                     text_index = 0, spliter_delimiter = '\\n',\n",
        "                     )"
      ],
      "metadata": {
        "id": "5j1v9kzdisxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2SU7J1FjSKe",
        "outputId": "d1a65cd6-f8c7-45d1-d486-3dfc19a90a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['FROM fairest creatures we desire increase,',\n",
              " \"That thereby beauty's rose might never die,\",\n",
              " 'But as the riper should by time decease,',\n",
              " 'His tender heir might bear his memory:',\n",
              " 'But thou, contracted to thine own bright eyes,']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xws6QVTWPwbW"
      },
      "outputs": [],
      "source": [
        "#define tokenizer and sequences and padding sequences\n",
        "def texts_labels_generator(#define texts\n",
        "                           texts_list,\n",
        "                           #define filter characters list\n",
        "                           use_modified_filters = False, filters_list = None,\n",
        "                           #define json tokenizer\n",
        "                           save_tokenizer_json = False, tokenizer_filepath = None\n",
        "                           ):\n",
        "    \n",
        "    #define tokenizer filters and fit on texts\n",
        "    from keras.preprocessing.text import Tokenizer\n",
        "    if use_modified_filters:\n",
        "        filters = ''.join(filters_list)\n",
        "    else:\n",
        "        filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "\n",
        "    tokenizer = Tokenizer(filters = filters)\n",
        "    tokenizer.fit_on_texts(texts_list)\n",
        "\n",
        "    #define word_index\n",
        "    word_index = tokenizer.word_index\n",
        "    #for padding and counting out of vocab word\n",
        "    total_words = len(word_index) + 1\n",
        "\n",
        "    #save tokenizer json file\n",
        "    if save_tokenizer_json:\n",
        "        with open(tokenizer_filepath+'.json','w') as tokenizer_file:\n",
        "            json.dump(tokenizer.to_json(), tokenizer_file)\n",
        "\n",
        "    #define texts to sequences\n",
        "    texts_sequences = tokenizer.texts_to_sequences(texts_list)\n",
        "\n",
        "    #define phrase based sequences\n",
        "    phrases_sequences = list()\n",
        "\n",
        "    for text_sequence in texts_sequences:\n",
        "        for token_iter in range(1, len(text_sequence)):\n",
        "            phrase_sequence = text_sequence[:token_iter+1]\n",
        "            phrases_sequences.append(phrase_sequence)\n",
        "\n",
        "    #define maximum length of the sequences\n",
        "    maxlen = max([len(sequence) for sequence in phrases_sequences])\n",
        "\n",
        "    #define training validation pad sequences\n",
        "    from keras.preprocessing.sequence import pad_sequences\n",
        "    padded_sequences = pad_sequences(phrases_sequences, maxlen = maxlen, padding = 'pre')\n",
        "\n",
        "    #split texts and labels\n",
        "    texts = padded_sequences[:,:-1]\n",
        "    labels = padded_sequences[:,-1]\n",
        "\n",
        "    return texts, labels, maxlen, tokenizer, word_index\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels, maxlen, tokenizer, word_index = texts_labels_generator(#define texts\n",
        "                                                                                   texts_list = texts,\n",
        "                                                                                   #define filter characters list\n",
        "                                                                                   use_modified_filters = False, filters_list = None,\n",
        "                                                                                   #define json tokenizer\n",
        "                                                                                   save_tokenizer_json = False, tokenizer_filepath = None)"
      ],
      "metadata": {
        "id": "wZEZqql-jcGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGSfyqvijnDh",
        "outputId": "e8550193-91ac-4d96-e761-c1410ed7385c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    0,   34],\n",
              "       [   0,    0,    0, ...,    0,   34,  417],\n",
              "       [   0,    0,    0, ...,   34,  417,  877],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 3209,  493,  493],\n",
              "       [   0,    0,    0, ...,  493,  493, 3210],\n",
              "       [   0,    0,    0, ...,  493, 3210,   15]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlUz5XBTkXzd",
        "outputId": "f8c14eea-1381-49d0-9cc6-fc83c7d54a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 417,  877,  166, ..., 3210,   15,   14], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJ3p8PBDbFH2"
      },
      "outputs": [],
      "source": [
        "#define labels encoder\n",
        "def label_encoder(#define labels list and method\n",
        "                  labels_list,\n",
        "                  #define method binary, ordinal or onehot\n",
        "                  method, return_categories = True\n",
        "                  ):\n",
        "    \n",
        "    #ordinal and binary encoder method\n",
        "    if method in ['binary','ordinal']:\n",
        "        unique_labels = sorted(list(set(labels_list)))\n",
        "        labels_dict = {\n",
        "            label : int(unique_labels.index(label)) for label in unique_labels\n",
        "        }\n",
        "        labels = list(map(lambda label : labels_dict[label], labels_list))\n",
        "    \n",
        "    #one-hot encoder method\n",
        "    elif method in ['onehot']:\n",
        "        unique_labels = sorted(list(set(labels_list)))\n",
        "        labels_dict = {\n",
        "            label : int(unique_labels.index(label)) for label in unique_labels\n",
        "        }\n",
        "        labels_encoded = list()\n",
        "        for label in labels_list:\n",
        "            label_encoded = len(unique_labels)*[0]\n",
        "            label_number = labels_dict[label]\n",
        "            label_encoded[label_number] = 1\n",
        "            labels_encoded.append(label_encoded)\n",
        "        labels = labels_encoded\n",
        "\n",
        "    #convert list type to array\n",
        "    labels_encoded = np.array(labels)\n",
        "    \n",
        "    if return_categories:\n",
        "        return labels_encoded, labels_dict\n",
        "    else:\n",
        "        return labels_encoded\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_encoded, labels_dict = label_encoder(#define labels list and method\n",
        "                                            labels_list = labels,\n",
        "                                            #define method binary, ordinal or onehot\n",
        "                                            method = 'onehot', return_categories = True\n",
        "                                            )\n"
      ],
      "metadata": {
        "id": "VYsK1ZRQkk-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxWfT2f9k3Yl",
        "outputId": "b9d82afc-c492-4c61-fe50-02e26579ec97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRHnC1EAk5ke",
        "outputId": "5f1fe747-0066-4d69-99b0-31d4007c9b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15462, 3083)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define pre-trained words dictionary loader\n",
        "def word_dict_loader(#define file path and file type\n",
        "                     file_path, file_type,\n",
        "                     #define txt and csv file type args\n",
        "                     word_index = None, vector_index = None, header = True, spliter_delimiter = None,\n",
        "                     use_word_spliter = False, word_spliter = None, word_split_index = None,\n",
        "                     #define json file type args\n",
        "                     word_key = None, vector_key = None,\n",
        "                     ):\n",
        "    \n",
        "    word_dict = dict()\n",
        "\n",
        "    #define txt vec loader\n",
        "    if file_type in ['txt', 'vec']:\n",
        "        with open(file_path, 'r') as word_dict_file:\n",
        "            if header:\n",
        "                next(word_dict_file)\n",
        "            for row in word_dict_file:\n",
        "                row = row.split(spliter_delimiter)\n",
        "                if use_word_spliter:\n",
        "                    word = row[word_index].split(word_spliter)[word_split_index]\n",
        "                else:\n",
        "                    word = row[word_index]\n",
        "                vectors = np.array(row[vector_index:], dtype = 'float32')\n",
        "                word_dict[word] = vectors\n",
        "\n",
        "    #define csv loader\n",
        "    elif file_type in ['csv']:\n",
        "        with open(file_path, 'r') as word_dict_file:\n",
        "            word_dict_file = csv.reader(word_dict_file, delimiter = spliter_delimiter)\n",
        "            if header:\n",
        "                next(word_dict_file)\n",
        "            for row in word_dict_file:\n",
        "                if use_word_spliter:\n",
        "                    word = row[word_index].split(word_spliter)[word_split_index]\n",
        "                else:\n",
        "                    word = row[word_index]\n",
        "                vectors = np.array(row[vector_index:], dtype = 'float32')\n",
        "                word_dict[word] = vectors\n",
        "                \n",
        "    #define json loader\n",
        "    elif file_type in ['json']:\n",
        "        with open(file_path, 'r') as word_dict_file:\n",
        "            word_dict_file = json.load(word_dict_file)\n",
        "            for item in word_dict_file:\n",
        "                word = item[word_key]\n",
        "                vectors = np.array(item[vector_key], dtype = 'float32')\n",
        "                word_dict[word] = vectors\n",
        "\n",
        "    #word dict params\n",
        "    word_dict_size = len(word_dict)\n",
        "    word_dict_dim = list(word_dict.values())[0].shape[0]\n",
        "\n",
        "    return word_dict, word_dict_size, word_dict_dim\n"
      ],
      "metadata": {
        "id": "brRWvKPSp4QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define pre-trained embedding word vectors\n",
        "def embd_weights_loader(#define word dictionary and word index\n",
        "                        word_dict, word_index, dimension\n",
        "                        ):\n",
        "    \n",
        "    #create embedding weights\n",
        "    embed_weights = np.zeros([len(word_index)+1, dimension])\n",
        "\n",
        "    for word, index in word_index.items():\n",
        "        if word in word_dict:\n",
        "            embed_weights[index] = word_dict[word]\n",
        "\n",
        "    #embedding layer params\n",
        "    vocab_size = embed_weights.shape[0]\n",
        "    embed_dim = embed_weights.shape[1]\n",
        "\n",
        "    return embed_weights, vocab_size, embed_dim\n"
      ],
      "metadata": {
        "id": "fFr4DSbYpYjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlRqac9W2DWL"
      },
      "outputs": [],
      "source": [
        "#define model\n",
        "def create_model(#define input shape\n",
        "                 input_shape = None,\n",
        "                 #define embedding layer parameters\n",
        "                 use_pretraind_embd = False, vocab_size = None, embd_dim = None,\n",
        "                 sequence_len = None, embed_weights = None,\n",
        "                 #define type of layer and parameters\n",
        "                 use_lstm = False, use_gru = False, use_conv = False,\n",
        "                 #define lstm layers parameters\n",
        "                 lstm_layers_num = None, lstm_layers_units = None,\n",
        "                 #define gru layers parameters\n",
        "                 gru_layers_num = None, gru_layers_units = None,\n",
        "                 #define convolution layers parameters\n",
        "                 conv_layers_num = None, conv_layers_filters = None, conv_layers_kernel = None,\n",
        "                 #define convolution layers sub layers\n",
        "                 use_max_pool = False, max_pool_size = None,\n",
        "                 #define dense layer feeder\n",
        "                 use_global_max_pool = False, use_global_avg_pool = False, use_flatten = False,\n",
        "                 use_feeder_dropout = False, feeder_dropout_ratio = None,\n",
        "                 #define dense head layers\n",
        "                 use_dense_layer = False, dense_layers_num = None, dense_layers_units = None,\n",
        "                 #define dense layers dropout parameters\n",
        "                 use_dense_dropout = False, dense_dropout_ratio = None,\n",
        "                 #define output layer parameters\n",
        "                 output_layer_unit = None, output_layer_activation = None,\n",
        "                 #define model compiler parameters\n",
        "                 optimizer = None, loss = None, metrics = None\n",
        "                 ):\n",
        "    \n",
        "    #define input layer\n",
        "    input = keras.Input(shape = input_shape)\n",
        "\n",
        "    #define embedding layer and parameters\n",
        "    if use_pretraind_embd:\n",
        "        out = keras.layers.Embedding(input_dim = vocab_size, output_dim = embd_dim, input_length = sequence_len,\n",
        "                                     weights = [embed_weights], trainable = False)(input)\n",
        "    else:\n",
        "        out = keras.layers.Embedding(input_dim = vocab_size, output_dim = embd_dim, input_length = sequence_len)(input)\n",
        "\n",
        "    #define type of layer and parameters\n",
        "    #lstm type layers\n",
        "    if use_lstm:\n",
        "        sequence_return = (lstm_layers_num - 1)*[True]\n",
        "        sequence_return.append(False)\n",
        "        for layer_num in range(lstm_layers_num):\n",
        "            out = keras.layers.Bidirectional(keras.layers.LSTM(lstm_layers_units[layer_num],\n",
        "                                                               return_sequences = sequence_return[layer_num]))(out)\n",
        "\n",
        "    #gru type layers\n",
        "    elif use_gru:\n",
        "        sequence_return = (gru_layers_num - 1)*[True]\n",
        "        sequence_return.append(False)\n",
        "        for layer_num in range(gru_layers_num):\n",
        "            out = keras.layers.Bidirectional(keras.layers.GRU(gru_layers_units[layer_num],\n",
        "                                                              return_sequences = sequence_return[layer_num]))(out)\n",
        "    \n",
        "    #convolution type layer\n",
        "    elif use_conv:\n",
        "        for layer_num in range(conv_layers_num):\n",
        "            out = keras.layers.Conv1D(filters = conv_layers_filters[layer_num], kernel_size = conv_layers_kernel[layer_num],\n",
        "                                      activation = 'relu')(out)\n",
        "            if use_max_pool[layer_num]:\n",
        "                out = keras.layers.MaxPool1D(max_pool_size[layer_num])(out)\n",
        "\n",
        "\n",
        "    #dense layers feeder layer\n",
        "    #global max pool type layer\n",
        "    if use_global_max_pool:\n",
        "        out = keras.layers.GlobalMaxPooling1D()(out)\n",
        "        \n",
        "    #global average pool type layer\n",
        "    elif use_global_avg_pool:\n",
        "        out = keras.layers.GlobalAveragePooling1D()(out)\n",
        "\n",
        "    #flatten type layer\n",
        "    elif use_flatten:\n",
        "        out = keras.layers.Flatten()(out)\n",
        "\n",
        "    #define feeder dropout layer\n",
        "    if use_feeder_dropout:\n",
        "        out = keras.layers.Dropout(feeder_dropout_ratio)(out)\n",
        "\n",
        "\n",
        "    #define dense head layers\n",
        "    if use_dense_layer:\n",
        "        for layer_num in range(dense_layers_num):\n",
        "            out = keras.layers.Dense(dense_layers_units[layer_num], activation = 'relu')(out)\n",
        "            if use_dense_dropout[layer_num]:\n",
        "                out = keras.layers.Dropout(dense_dropout_ratio[layer_num])(out)\n",
        "    \n",
        "    #define output layer\n",
        "    output = keras.layers.Dense(output_layer_unit, activation = output_layer_activation)(out)\n",
        "\n",
        "    #define model\n",
        "    model = keras.models.Model(inputs = input, outputs = output)\n",
        "\n",
        "\n",
        "    #compile model\n",
        "    model.compile(optimizer = optimizer,\n",
        "                  loss = loss,\n",
        "                  metrics = metrics)\n",
        "    \n",
        "    return model\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(#define input shape\n",
        "                     input_shape = maxlen - 1,\n",
        "                     #define embedding layer parameters\n",
        "                     use_pretraind_embd = False, vocab_size = len(word_index) + 1 , embd_dim = 128,\n",
        "                     sequence_len = maxlen - 1, embed_weights = None,\n",
        "                     #define type of layer and parameters\n",
        "                     use_lstm = True, use_gru = False, use_conv = False,\n",
        "                     #define lstm layers parameters\n",
        "                     lstm_layers_num = 2, lstm_layers_units = [64, 128],\n",
        "                     #define gru layers parameters\n",
        "                     gru_layers_num = None, gru_layers_units = None,\n",
        "                     #define convolution layers parameters\n",
        "                     conv_layers_num = None, conv_layers_filters = None, conv_layers_kernel = None,\n",
        "                     #define convolution layers sub layers\n",
        "                     use_max_pool = False, max_pool_size = None,\n",
        "                     #define dense layer feeder\n",
        "                     use_global_max_pool = False, use_global_avg_pool = False, use_flatten = False,\n",
        "                     use_feeder_dropout = True, feeder_dropout_ratio = 0.2,\n",
        "                     #define dense head layers\n",
        "                     dense_layers_num = None, dense_layers_units = None,\n",
        "                     #define dense layers dropout parameters\n",
        "                     use_dense_dropout = False, dense_dropout_ratio = None,\n",
        "                     #define output layer parameters\n",
        "                     output_layer_unit = len(labels_dict), output_layer_activation = 'softmax',\n",
        "                     #define model compiler parameters\n",
        "                     optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy'\n",
        "                     )"
      ],
      "metadata": {
        "id": "7cApqHwGmYYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model summary\n",
        "model.summary(120)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoM66pE6oxL0",
        "outputId": "1a267600-5aa3-49bf-8d62-688373b7e96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "________________________________________________________________________________________________________________________\n",
            " Layer (type)                                         Output Shape                                    Param #           \n",
            "========================================================================================================================\n",
            " input_1 (InputLayer)                                 [(None, 10)]                                    0                 \n",
            "                                                                                                                        \n",
            " embedding (Embedding)                                (None, 10, 128)                                 411008            \n",
            "                                                                                                                        \n",
            " bidirectional (Bidirectional)                        (None, 10, 128)                                 98816             \n",
            "                                                                                                                        \n",
            " bidirectional_1 (Bidirectional)                      (None, 256)                                     263168            \n",
            "                                                                                                                        \n",
            " dropout (Dropout)                                    (None, 256)                                     0                 \n",
            "                                                                                                                        \n",
            " dense (Dense)                                        (None, 3083)                                    792331            \n",
            "                                                                                                                        \n",
            "========================================================================================================================\n",
            "Total params: 1,565,323\n",
            "Trainable params: 1,565,323\n",
            "Non-trainable params: 0\n",
            "________________________________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fit model\n",
        "model.fit(texts, labels_encoded, epochs = 500)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQcBis-no21v",
        "outputId": "347ece90-f401-414a-d666-b35559004176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "484/484 [==============================] - 37s 60ms/step - loss: 6.8190 - accuracy: 0.0232\n",
            "Epoch 2/500\n",
            "484/484 [==============================] - 28s 58ms/step - loss: 6.4563 - accuracy: 0.0340\n",
            "Epoch 3/500\n",
            "484/484 [==============================] - 28s 59ms/step - loss: 6.3044 - accuracy: 0.0382\n",
            "Epoch 4/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 6.1648 - accuracy: 0.0417\n",
            "Epoch 5/500\n",
            "484/484 [==============================] - 28s 58ms/step - loss: 6.0065 - accuracy: 0.0460\n",
            "Epoch 6/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 5.8443 - accuracy: 0.0528\n",
            "Epoch 7/500\n",
            "484/484 [==============================] - 28s 58ms/step - loss: 5.6795 - accuracy: 0.0612\n",
            "Epoch 8/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 5.5107 - accuracy: 0.0636\n",
            "Epoch 9/500\n",
            "484/484 [==============================] - 31s 63ms/step - loss: 5.3364 - accuracy: 0.0734\n",
            "Epoch 10/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 5.1565 - accuracy: 0.0797\n",
            "Epoch 11/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 4.9775 - accuracy: 0.0897\n",
            "Epoch 12/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 4.7920 - accuracy: 0.1017\n",
            "Epoch 13/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 4.6114 - accuracy: 0.1157\n",
            "Epoch 14/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 4.4254 - accuracy: 0.1367\n",
            "Epoch 15/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 4.2378 - accuracy: 0.1573\n",
            "Epoch 16/500\n",
            "484/484 [==============================] - 31s 63ms/step - loss: 4.0474 - accuracy: 0.1858\n",
            "Epoch 17/500\n",
            "484/484 [==============================] - 31s 63ms/step - loss: 3.8574 - accuracy: 0.2088\n",
            "Epoch 18/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 3.6755 - accuracy: 0.2428\n",
            "Epoch 19/500\n",
            "484/484 [==============================] - 31s 63ms/step - loss: 3.5081 - accuracy: 0.2682\n",
            "Epoch 20/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 3.3296 - accuracy: 0.2968\n",
            "Epoch 21/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 3.1611 - accuracy: 0.3320\n",
            "Epoch 22/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 3.0110 - accuracy: 0.3564\n",
            "Epoch 23/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 2.8624 - accuracy: 0.3853\n",
            "Epoch 24/500\n",
            "484/484 [==============================] - 28s 59ms/step - loss: 2.7157 - accuracy: 0.4144\n",
            "Epoch 25/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 2.5897 - accuracy: 0.4357\n",
            "Epoch 26/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 2.4601 - accuracy: 0.4627\n",
            "Epoch 27/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 2.3429 - accuracy: 0.4862\n",
            "Epoch 28/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 2.2327 - accuracy: 0.5083\n",
            "Epoch 29/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 2.1223 - accuracy: 0.5306\n",
            "Epoch 30/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 2.0310 - accuracy: 0.5521\n",
            "Epoch 31/500\n",
            "484/484 [==============================] - 28s 59ms/step - loss: 1.9348 - accuracy: 0.5718\n",
            "Epoch 32/500\n",
            "484/484 [==============================] - 28s 58ms/step - loss: 1.8355 - accuracy: 0.5933\n",
            "Epoch 33/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 1.7700 - accuracy: 0.6028\n",
            "Epoch 34/500\n",
            "484/484 [==============================] - 28s 58ms/step - loss: 1.6842 - accuracy: 0.6262\n",
            "Epoch 35/500\n",
            "484/484 [==============================] - 28s 58ms/step - loss: 1.6106 - accuracy: 0.6431\n",
            "Epoch 36/500\n",
            "484/484 [==============================] - 28s 58ms/step - loss: 1.5467 - accuracy: 0.6541\n",
            "Epoch 37/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 1.4828 - accuracy: 0.6691\n",
            "Epoch 38/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 1.4205 - accuracy: 0.6848\n",
            "Epoch 39/500\n",
            "484/484 [==============================] - 31s 63ms/step - loss: 1.3679 - accuracy: 0.6931\n",
            "Epoch 40/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 1.3167 - accuracy: 0.7022\n",
            "Epoch 41/500\n",
            "484/484 [==============================] - 32s 66ms/step - loss: 1.2685 - accuracy: 0.7128\n",
            "Epoch 42/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 1.2262 - accuracy: 0.7267\n",
            "Epoch 43/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 1.1857 - accuracy: 0.7297\n",
            "Epoch 44/500\n",
            "484/484 [==============================] - 31s 65ms/step - loss: 1.1438 - accuracy: 0.7398\n",
            "Epoch 45/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 1.1129 - accuracy: 0.7467\n",
            "Epoch 46/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 1.0753 - accuracy: 0.7555\n",
            "Epoch 47/500\n",
            "484/484 [==============================] - 31s 65ms/step - loss: 1.0378 - accuracy: 0.7661\n",
            "Epoch 48/500\n",
            "484/484 [==============================] - 31s 63ms/step - loss: 1.0199 - accuracy: 0.7637\n",
            "Epoch 49/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.9898 - accuracy: 0.7742\n",
            "Epoch 50/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 0.9575 - accuracy: 0.7819\n",
            "Epoch 51/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 0.9470 - accuracy: 0.7820\n",
            "Epoch 52/500\n",
            "484/484 [==============================] - 32s 67ms/step - loss: 0.9238 - accuracy: 0.7872\n",
            "Epoch 53/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.8913 - accuracy: 0.7923\n",
            "Epoch 54/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.8809 - accuracy: 0.7939\n",
            "Epoch 55/500\n",
            "484/484 [==============================] - 32s 66ms/step - loss: 0.8661 - accuracy: 0.8009\n",
            "Epoch 56/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.8516 - accuracy: 0.8013\n",
            "Epoch 57/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.8386 - accuracy: 0.8024\n",
            "Epoch 58/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.8333 - accuracy: 0.8038\n",
            "Epoch 59/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.8174 - accuracy: 0.8064\n",
            "Epoch 60/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.7970 - accuracy: 0.8097\n",
            "Epoch 61/500\n",
            "484/484 [==============================] - 32s 66ms/step - loss: 0.7899 - accuracy: 0.8132\n",
            "Epoch 62/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.7880 - accuracy: 0.8133\n",
            "Epoch 63/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.7577 - accuracy: 0.8185\n",
            "Epoch 64/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.7577 - accuracy: 0.8179\n",
            "Epoch 65/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.7409 - accuracy: 0.8214\n",
            "Epoch 66/500\n",
            "484/484 [==============================] - 29s 59ms/step - loss: 0.7428 - accuracy: 0.8219\n",
            "Epoch 67/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 0.7231 - accuracy: 0.8245\n",
            "Epoch 68/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.7242 - accuracy: 0.8269\n",
            "Epoch 69/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.7259 - accuracy: 0.8243\n",
            "Epoch 70/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.7173 - accuracy: 0.8272\n",
            "Epoch 71/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.7156 - accuracy: 0.8277\n",
            "Epoch 72/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.7099 - accuracy: 0.8289\n",
            "Epoch 73/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6981 - accuracy: 0.8287\n",
            "Epoch 74/500\n",
            "484/484 [==============================] - 28s 58ms/step - loss: 0.6929 - accuracy: 0.8299\n",
            "Epoch 75/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.6866 - accuracy: 0.8325\n",
            "Epoch 76/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.6833 - accuracy: 0.8320\n",
            "Epoch 77/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 0.6845 - accuracy: 0.8321\n",
            "Epoch 78/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6842 - accuracy: 0.8287\n",
            "Epoch 79/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6645 - accuracy: 0.8327\n",
            "Epoch 80/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 0.6664 - accuracy: 0.8355\n",
            "Epoch 81/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6649 - accuracy: 0.8351\n",
            "Epoch 82/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.6572 - accuracy: 0.8366\n",
            "Epoch 83/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.6462 - accuracy: 0.8394\n",
            "Epoch 84/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.6492 - accuracy: 0.8389\n",
            "Epoch 85/500\n",
            "484/484 [==============================] - 29s 59ms/step - loss: 0.6482 - accuracy: 0.8377\n",
            "Epoch 86/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6441 - accuracy: 0.8385\n",
            "Epoch 87/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.6412 - accuracy: 0.8375\n",
            "Epoch 88/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.6464 - accuracy: 0.8379\n",
            "Epoch 89/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.6467 - accuracy: 0.8366\n",
            "Epoch 90/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6540 - accuracy: 0.8366\n",
            "Epoch 91/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6450 - accuracy: 0.8363\n",
            "Epoch 92/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 0.6296 - accuracy: 0.8406\n",
            "Epoch 93/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.6289 - accuracy: 0.8403\n",
            "Epoch 94/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.6367 - accuracy: 0.8390\n",
            "Epoch 95/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.6191 - accuracy: 0.8432\n",
            "Epoch 96/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.6289 - accuracy: 0.8383\n",
            "Epoch 97/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6170 - accuracy: 0.8438\n",
            "Epoch 98/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6269 - accuracy: 0.8404\n",
            "Epoch 99/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6093 - accuracy: 0.8429\n",
            "Epoch 100/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.6225 - accuracy: 0.8402\n",
            "Epoch 101/500\n",
            "484/484 [==============================] - 31s 63ms/step - loss: 0.6225 - accuracy: 0.8395\n",
            "Epoch 102/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.6131 - accuracy: 0.8432\n",
            "Epoch 103/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6174 - accuracy: 0.8426\n",
            "Epoch 104/500\n",
            "484/484 [==============================] - 29s 59ms/step - loss: 0.6174 - accuracy: 0.8408\n",
            "Epoch 105/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.6029 - accuracy: 0.8445\n",
            "Epoch 106/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.6096 - accuracy: 0.8432\n",
            "Epoch 107/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.5919 - accuracy: 0.8479\n",
            "Epoch 108/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5981 - accuracy: 0.8453\n",
            "Epoch 109/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.6069 - accuracy: 0.8438\n",
            "Epoch 110/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.6080 - accuracy: 0.8432\n",
            "Epoch 111/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.6059 - accuracy: 0.8436\n",
            "Epoch 112/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.6044 - accuracy: 0.8419\n",
            "Epoch 113/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.6031 - accuracy: 0.8435\n",
            "Epoch 114/500\n",
            "484/484 [==============================] - 29s 59ms/step - loss: 0.6059 - accuracy: 0.8404\n",
            "Epoch 115/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5872 - accuracy: 0.8470\n",
            "Epoch 116/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5872 - accuracy: 0.8457\n",
            "Epoch 117/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5892 - accuracy: 0.8465\n",
            "Epoch 118/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.5914 - accuracy: 0.8447\n",
            "Epoch 119/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5897 - accuracy: 0.8447\n",
            "Epoch 120/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.6002 - accuracy: 0.8423\n",
            "Epoch 121/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5973 - accuracy: 0.8425\n",
            "Epoch 122/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5887 - accuracy: 0.8459\n",
            "Epoch 123/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.5788 - accuracy: 0.8486\n",
            "Epoch 124/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5956 - accuracy: 0.8422\n",
            "Epoch 125/500\n",
            "484/484 [==============================] - 29s 59ms/step - loss: 0.5886 - accuracy: 0.8465\n",
            "Epoch 126/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5791 - accuracy: 0.8479\n",
            "Epoch 127/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.5752 - accuracy: 0.8467\n",
            "Epoch 128/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5796 - accuracy: 0.8476\n",
            "Epoch 129/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5884 - accuracy: 0.8435\n",
            "Epoch 130/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.5824 - accuracy: 0.8461\n",
            "Epoch 131/500\n",
            "484/484 [==============================] - 29s 59ms/step - loss: 0.5801 - accuracy: 0.8476\n",
            "Epoch 132/500\n",
            "484/484 [==============================] - 31s 65ms/step - loss: 0.5832 - accuracy: 0.8442\n",
            "Epoch 133/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 0.5815 - accuracy: 0.8454\n",
            "Epoch 134/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 0.5747 - accuracy: 0.8462\n",
            "Epoch 135/500\n",
            "484/484 [==============================] - 31s 63ms/step - loss: 0.5760 - accuracy: 0.8464\n",
            "Epoch 136/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.5703 - accuracy: 0.8489\n",
            "Epoch 137/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.5736 - accuracy: 0.8465\n",
            "Epoch 138/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.5663 - accuracy: 0.8484\n",
            "Epoch 139/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.5831 - accuracy: 0.8453\n",
            "Epoch 140/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.5912 - accuracy: 0.8418\n",
            "Epoch 141/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.5701 - accuracy: 0.8474\n",
            "Epoch 142/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.5695 - accuracy: 0.8467\n",
            "Epoch 143/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.5731 - accuracy: 0.8479\n",
            "Epoch 144/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.5720 - accuracy: 0.8463\n",
            "Epoch 145/500\n",
            "484/484 [==============================] - 29s 59ms/step - loss: 0.5680 - accuracy: 0.8476\n",
            "Epoch 146/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.5665 - accuracy: 0.8481\n",
            "Epoch 147/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5734 - accuracy: 0.8465\n",
            "Epoch 148/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 0.5659 - accuracy: 0.8476\n",
            "Epoch 149/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.5717 - accuracy: 0.8469\n",
            "Epoch 150/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.5729 - accuracy: 0.8455\n",
            "Epoch 151/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.5622 - accuracy: 0.8477\n",
            "Epoch 152/500\n",
            "484/484 [==============================] - 29s 61ms/step - loss: 0.5543 - accuracy: 0.8497\n",
            "Epoch 153/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.5592 - accuracy: 0.8484\n",
            "Epoch 154/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.5627 - accuracy: 0.8498\n",
            "Epoch 155/500\n",
            "484/484 [==============================] - 30s 62ms/step - loss: 0.5623 - accuracy: 0.8471\n",
            "Epoch 156/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.5617 - accuracy: 0.8483\n",
            "Epoch 157/500\n",
            "484/484 [==============================] - 29s 59ms/step - loss: 0.5620 - accuracy: 0.8491\n",
            "Epoch 158/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5603 - accuracy: 0.8496\n",
            "Epoch 159/500\n",
            "484/484 [==============================] - 29s 60ms/step - loss: 0.5603 - accuracy: 0.8474\n",
            "Epoch 160/500\n",
            "484/484 [==============================] - 30s 63ms/step - loss: 0.5653 - accuracy: 0.8469\n",
            "Epoch 161/500\n",
            "484/484 [==============================] - 30s 61ms/step - loss: 0.5648 - accuracy: 0.8463\n",
            "Epoch 162/500\n",
            "484/484 [==============================] - 31s 63ms/step - loss: 0.5573 - accuracy: 0.8480\n",
            "Epoch 163/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.5573 - accuracy: 0.8479\n",
            "Epoch 164/500\n",
            "484/484 [==============================] - 31s 63ms/step - loss: 0.5645 - accuracy: 0.8479\n",
            "Epoch 165/500\n",
            "484/484 [==============================] - 32s 66ms/step - loss: 0.5630 - accuracy: 0.8459\n",
            "Epoch 166/500\n",
            "484/484 [==============================] - 31s 64ms/step - loss: 0.5579 - accuracy: 0.8478\n",
            "Epoch 167/500\n",
            "306/484 [=================>............] - ETA: 11s - loss: 0.5381 - accuracy: 0.8527"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot model training loss\n",
        "pd.DataFrame(model.history.history)[['loss']].plot(figsize = (9, 6), linewidth = 3)\n",
        "plt.grid(linestyle = '--', linewidth = 2)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "r9WlvK5vzfSG",
        "outputId": "39cf0da2-311d-44b6-beff-2dfb756f9070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot model training accuracy\n",
        "pd.DataFrame(model.history.history)[['accuracy']].plot(figsize = (9, 6), linewidth = 3)\n",
        "plt.grid(linestyle = '--', linewidth = 2)\n",
        "plt.ylim(0,1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "v4gmV_f1z1nM",
        "outputId": "641f88f7-50db-4839-f511-e3e581f38225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "train_set_eval = model.evaluate(texts, labels_encoded, verbose = 0)\n",
        "print(f'Training Set Evaluation:\\n\\tLoss: {round(train_set_eval[0],4)}\\tAccuracy: {100*round(train_set_eval[1],4)}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1fGgl5a0Ms8",
        "outputId": "cf9aa20b-2a9f-4549-cc7d-16d3f84a3a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Evaluation:\n",
            "\tLoss: 0.4292\tAccuracy: 86.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define text generator based on model\n",
        "def text_generator(#define text and numbert of iteration\n",
        "                   input_text, iteration,\n",
        "                   #define tokenizer and maxlen\n",
        "                   tokenizer, maxlen, word_index,\n",
        "                   #define labels categories and model\n",
        "                   labels_dict, model, \n",
        "                   ):\n",
        "    \n",
        "    input_text = str(input_text)\n",
        "    key_values_labels = dict([(key,value) for value, key in labels_dict.items()])\n",
        "    index_word = dict([(key, value) for value, key in word_index.items()])\n",
        "\n",
        "    for iter in range(iteration):\n",
        "        text = tokenizer.texts_to_sequences([input_text])\n",
        "        text = keras.preprocessing.sequence.pad_sequences(text, padding = 'pre', maxlen = maxlen - 1)\n",
        "        predict = model.predict(text)\n",
        "        predict = np.argmax(predict, axis = -1)[0]\n",
        "        predict = key_values_labels[predict]\n",
        "        predict = index_word[predict]\n",
        "        input_text = input_text + \" \" + predict\n",
        "    \n",
        "    return input_text.title()\n"
      ],
      "metadata": {
        "id": "4veh4dxp72m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate the text\n",
        "generated_text = text_generator(#define text and numbert of iteration\n",
        "                                input_text = 'We Never Die In Heart', iteration = 20,\n",
        "                                #define tokenizer and maxlen\n",
        "                                tokenizer = tokenizer, maxlen = maxlen, word_index = word_index,\n",
        "                                #define labels categories and model\n",
        "                                labels_dict = labels_dict, model = model,\n",
        "                                )\n",
        "#print out the generated text\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmfAFEdhLQKq",
        "outputId": "69f6edc8-3ad3-4364-d2c5-3f01a0ad28c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We Never Die In Heart To Single Cherish Lie Of Thy Deeds ' Of Me Loves Gone Kings Thence Random On Me Date Forth Me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "model.save('/content/model.h5')\n"
      ],
      "metadata": {
        "id": "gikdU4aO0Lgg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "shakespeare-sonnets-text-generation.ipynb",
      "provenance": [],
      "mount_file_id": "1YqkKxxHYU3J4ituglLL786xGYjnko5FS",
      "authorship_tag": "ABX9TyPsnQJ4H5dOnMGp3K+gS4og",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}